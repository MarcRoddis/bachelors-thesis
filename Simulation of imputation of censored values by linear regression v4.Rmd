---
title: "Simulation of imputation of censored values by linear regression v4"
author: "Marc Roddis"
date: "6/28/2020"
output: html_document
---

```{r chunk1, include=FALSE}
library(RCurl)
library(tidyverse)
library(styler)
library(gridExtra)
library(cowplot)
library("NADA")
knitr::opts_chunk$set(echo=FALSE)
```

We will first create a test dataset `test_data1` from `pcb.csv` by omitting all missing values of `CB28` and `CB153`, removing all observations except those from herring species, removing all observations prior to 1989, re-indexing 1989 as "year zero", removing all variables except `YEAR`, `CB28` and `CB153`.

```{r chunk2, include=FALSE}
pcb_df <- read_csv("pcb.csv")
pcb_tib <- as_tibble(pcb_df)
testdata1 <- pcb_tib %>%
  mutate(CB28 = ifelse(CB28< -8, NA, CB28) ) %>%
  mutate(CB153 = ifelse(CB153< -8, NA, CB153) ) %>%
  mutate(CB28 = ifelse(CB28> -0.0001 & CB28< 0.0001, NA, CB28) ) %>%
  filter(!is.na(CB28)) %>%
  filter(!is.na(CB153)) %>%
  filter(SPECIES == "Herring") %>%
  filter(YEAR >= 1989) %>%
  mutate(YEAR = YEAR-1989) %>%
  select(YEAR, CB28, CB153)
```

We now create `testdata_cen_omit` by omitting all censored observations and replacing concentrations with log-concentrations.

```{r chunk3, include=FALSE}
geomean <- function(x) round(exp(mean( log(x) ) ),4)
testdata_cen_omit <- testdata1 %>%
  filter(CB28>0) %>%
  filter(CB153>0) %>%
  group_by(YEAR) %>%
  summarise_at(vars(CB28,CB153), geomean  ) %>%
  ungroup()
testdata_cen_omit_logconc <- testdata_cen_omit %>%
  mutate(CB28 = log(CB28)) %>%
  mutate(CB153 = log(CB153))
```

```{r chunk4}
# attach(testdata_cen_omit)
# glimpse(CB28)
# glimpse(CB153)
# glimpse(YEAR)
# plot(CB28 ~ YEAR)
# plot(CB153 ~ YEAR)
# plot(CB28 ~ CB153)
# summary(lm(CB28~YEAR))
# summary(lm(CB153~YEAR))
# summary(lm(CB28~CB153))
```

```{r chunk5}
# attach(testdata_cen_omit_logconc) # assume logconcs have normal distribution
# glimpse(CB28)
# glimpse(CB153)
# glimpse(YEAR) # 29 years indexed as 0:28
# plot(CB153 ~ YEAR)
# plot(CB28 ~ CB153)
# summary(lm(CB28~YEAR)) # -4.54 - 0.046*YEAR
# summary(lm(CB153~YEAR)) # -1.85 - 0.039*YEAR
# summary(lm(CB28~CB153)) # -3.12 + 0.86*CB153
# summary(lm(CB28~CB153+YEAR)) #  -3.60 + 0.51*CB153 - 0.026*YEAR
# 
# sd(CB28) # 0.64
# sd(CB153) # 0.86
# quantile(CB28, probs=c(0.1,0.3,0.5,0.9) ) # (-5.76, -5.32, -5.22, -4.79)
```

The simulation data is generated by the code block below.

```{r chunk10, include=FALSE}
attach(testdata_cen_omit_logconc)
# This simulation uses parameters from testdata_cen_omit_logconc
LOQ_p10 <-  -5.76
LOQ_p50 <-  -5.22
LOQ_p90 <-  -4.79

# alpha28year <- -4.54
# beta28year <- -0.046
alpha153year <- -1.85
beta153year <- -0.039

# residualSE28year <- 0.25
# residualSE153year <- 0.32

alpha28_153 <- -3.12
beta28_153 <- 0.86
# residualSE28_153 <- 0.25
# residualSE28_153plusYEAR <- 0.20
set.seed(1)
year_sim <- rep(0:9, 12)
# since CB153 has no missing values use NOISE + (CB153 ~ YEAR) to simulate CB153 
cb153sim <- rnorm(12) * sd(CB153) + alpha153year + beta153year * year_sim 
# use NOISE + (CB28 ~ CB153) to simulate CB28 
# so that CB28 only depends on YEAR via CB153
cb28sim <- rnorm(12) * sd(CB28) + alpha28_153 + beta28_153 * cb153sim 

cbind_data <- cbind(cb28sim, cb153sim, year_sim)
sim_data <- as_tibble(cbind_data)
sim_data_mean <- sim_data %>%
  group_by(year_sim) %>%
  summarise_at(vars(cb28sim, cb153sim), mean  ) %>%
  ungroup()
```

Fitting a linear model to our complete simluated dataset `sim_data_mean` gives  $$CB28 = -4.7116719 -0.0334808 * YEAR$$ this is the gold standard against which will will evaluate our three methods for dealing with censored values.  We will test each method at various LOQ values.  For each method, at each LOQ value, we will find the mse, squared-bias, and variance, which we will use to evaluate the three methods.
 
```{r chunk10b}
# dim(sim_data)
# fit28_153 <- lm(sim_data$cb28sim ~ sim_data$cb153sim)
# summary(fit28_153)
# fit28_year <- lm(sim_data$cb28sim ~ sim_data$year_sim)
# summary(fit28_year)
# fit153_year <- lm(sim_data$cb153sim ~ sim_data$year_sim)
# summary(fit153_year)
# dim(sim_data_mean)
fit28_year_mean <- lm(sim_data_mean$cb28sim ~ sim_data_mean$year_sim)
summary(fit28_year_mean) # CB28 = -4.7116719 -0.0334808 * YEAR
predict_vec <- as.data.frame( predict(fit28_year_mean) )
str(predict_vec)


# fit28_153_mean <- lm(sim_data_mean$cb28sim ~ sim_data_mean$cb153sim)
# summary(fit28_153_mean)
# fit153_year_mean <- lm(sim_data_mean$cb153sim ~ sim_data_mean$year_sim)
# summary(fit153_year_mean)
```

We will now create simulated data for each of our three methods.

```{r chunk10c, eval=FALSE}
# should I calculate mse within this pipe using mse function in place of mean
# or should I do it like dalpiak: get new data, predict with each model
# for each year, separately.
# The big question is whether I am making separate predictions for every year.
sim_data_cen_p10_omit <- sim_data %>%
  mutate(cb28true = -4.7116719 -0.0334808 * year_sim) %>%
  filter(cb28sim>=LOQ_p10)
sim_data_cen_p10_omit
sim_data_mean_cen_p10_omit <- sim_data_cen_p10_omit %>%
  group_by(year_sim) %>%
  summarise_at(vars(cb28sim, cb153sim), mean  ) %>%
  ungroup()

sim_data_cen_p10_sub <- sim_data %>%
  mutate(cb28sim = pmax(cb28sim, LOQ_p10 - log(sqrt(2) ) ) ) 
sim_data_mean_cen_p10_sub <- sim_data_cen_p10_sub %>%
  group_by(year_sim) %>%
  summarise_at(vars(cb28sim, cb153sim), mean  ) %>%
  ungroup()

sim_data_cen_p10_cen_ind <- sim_data %>%
  mutate(ci28sim = cb28sim < LOQ_p10)
p10_cenreg_fit = cenreg(Cen(sim_data_cen_p10_cen_ind$cb28sim, sim_data_cen_p10_cen_ind$ci28sim)~ sim_data_cen_p10_cen_ind$cb153sim, dist="gaussian")
summary(p10_cenreg_fit)
# p10_cenreg_fit # cb28sim = -3.330 +0.728 * cb153sim
# signature(object="cenreg")
sim_data_cen_p10_cenreg_pred <- sim_data %>%
  mutate(cb28sim = ifelse(cb28sim < LOQ_p10, -3.330 + 0.728 * cb153sim, cb28sim))
sim_data_mean_cen_p10_cenreg_pred <- sim_data_cen_p10_cenreg_pred %>%
  group_by(year_sim) %>%
  summarise_at(vars(cb28sim, cb153sim), mean  ) %>%
  ungroup()
years <- c(0:9)
sim_data_all3_cbind <- cbind(years, -4.7116719 -0.0334808 * YEAR, sim_data_mean_cen_p10_omit$cb28sim, sim_data_mean_cen_p10_sub$cb28sim, sim_data_mean_cen_p10_cenreg_pred$cb28sim)
sim_data_all3_df <- data.frame(sim_data_all3_cbind)
colnames(sim_data_all3_df) <- c("Year", "Reference", "p10omit", "p10sub", "p10cenreg")
sim_data_all3_df
```



We will now find the mse, squared-bias and variance.

```{r chunk10e}
n_iter <- 5
set.seed(1)
years <- c(0:9)
geomean_prelogged <- function(x) exp(mean(x, na.rm = TRUE))

get_sim_data_best = function(sample_size=12) { 
  noise153 = rnorm(n = sample_size*10, mean = 0, sd = 0.5) # sd is from obs data
  noise28 = rnorm(n = sample_size*10, mean = 0, sd = 0.5) # sd is from obs data
  year = rep(years, sample_size)
  cb153 = -1.85 - 0.039 * year + noise153
  cb28 = -3.12 + 0.86*cb153 + noise28
  df = data.frame(year,cb28,cb153)
  data_tib2 = as_tibble(df)
  data_geomean2 <- data_tib2 %>%
    group_by(year) %>%
    summarise_at(vars(cb28, cb153), geomean_prelogged  ) %>%
    ungroup()
  data_geomean2
}

estimates_best <- matrix(0, nrow = 10, ncol = n_iter)

for (iter in 1:n_iter) {

  # simulate new, random, training data
  # this is the only random portion of the bias, var, and mse calculations
  # this allows us to calculate the expectation over the data

  sim_data_best <- get_sim_data_best(sample_size=12)
  best_fit = lm(sim_data_best$cb28 ~ sim_data_best$year)
  estimates_best[, iter] = predict(best_fit)
  data.frame(estimates_best)
}

best_annual_concs <-  exp(-4.711 - 0.03354 * years)
best_annual_means_n_iter <- rep(best_annual_concs, n_iter)
best_annual_means_matrix <- matrix(best_annual_means_n_iter, nrow=10, ncol=n_iter)
best_residuals_df <- data.frame(estimates_best - best_annual_means_matrix)

g = function(x) {
  mean(x^2)
}

best_mse_vector <- apply(best_residuals_df, 1, g)
best_mse_df <- data.frame(best_mse_vector)
estimates_best_mean = apply(estimates_best, 1, mean)
best_bias_sq_vector = (estimates_best_mean - best_annual_concs)^2
best_bias_sq_df = data.frame((best_bias_sq_vector))
best_variance_vector = apply(estimates_best, 1, var)
best_variance_df = data.frame(best_variance_vector)
best_mse_bias_sq_var_matrix = matrix(0, nrow = 10, ncol=3)
best_mse_bias_sq_var_matrix[,1] <- best_mse_vector
best_mse_bias_sq_var_matrix[,2] <- best_bias_sq_vector
best_mse_bias_sq_var_matrix[,3] <- best_variance_vector
best_mse_bias_sq_var_df <- data.frame(best_mse_bias_sq_var_matrix)
colnames(best_mse_bias_sq_var_df) <- c("mse_best","bias_best","variance_best")
best_mse_bias_sq_var_df

isTRUE(all.equal(best_bias_sq_vector + best_variance_vector, best_mse_vector) )

best_should_equal_mse = best_bias_sq_vector + best_variance_vector
best_decomp_misfit = best_should_equal_mse - best_mse_vector
best_decomp_misfit 

```

```{r chunk10e2a}

get_sim_data_p10_omit = function(sample_size=12) { 
  noise153 = rnorm(n = sample_size*10, mean = 0, sd = 0.5) # sd is from obs data
  noise28 = rnorm(n = sample_size*10, mean = 0, sd = 0.5) # sd is from obs data
  year = rep(years, sample_size)
  cb153 = -1.85 - 0.039 * year + noise153
  cb28 = -3.12 + 0.86*cb153 + noise28
  LOQ_p10 = quantile(cb28, probs= 0.1)
  df = data.frame(year,cb28,cb153)
  data_omit_tib = as_tibble(df)
  data_omit_geomean <- data_omit_tib %>%
    filter(cb28 >= LOQ_p10) %>%
    group_by(year) %>%
    summarise_at(vars(cb28, cb153), geomean_prelogged  ) %>%
    ungroup()
  data_omit_geomean
}

estimates_omit <- matrix(0, nrow = 10, ncol = n_iter)

for (iter in 1:n_iter) {

  # simulate new, random, training data
  # this is the only random portion of the bias, var, and mse calculations
  # this allows us to calculate the expectation over the data

  sim_omit_data <- get_sim_data_p10_omit(sample_size=12)
  omit_fit = lm(sim_omit_data$cb28 ~ sim_omit_data$year)
  estimates_omit[, iter] = predict(omit_fit)
  data.frame(estimates_omit)
}


best_annual_concs <-  exp(-4.711 - 0.03354 * years)
best_annual_means_n_iter <- rep(best_annual_concs, n_iter)
best_annual_means_matrix <- matrix(best_annual_means_n_iter, nrow=10, ncol=n_iter)

omit_residuals_df <- data.frame(estimates_omit - best_annual_means_matrix)

g = function(x) {
  mean(x^2)
}

omit_mse_vector <- apply(omit_residuals_df, 1, g)
omit_mse_df <- data.frame(omit_mse_vector)
estimates_omit_mean = apply(estimates_omit, 1, mean)
omit_bias_sq_vector = (estimates_omit_mean - best_annual_concs)^2

omit_bias_sq_df = data.frame((omit_bias_sq_vector))
omit_variance_vector = apply(estimates_omit, 1, var)
omit_variance_df = data.frame(omit_variance_vector)
omit_mse_bias_sq_var_matrix = matrix(0, nrow = 10, ncol=3)
omit_mse_bias_sq_var_matrix[,1] <- omit_mse_vector
omit_mse_bias_sq_var_matrix[,2] <- omit_bias_sq_vector
omit_mse_bias_sq_var_matrix[,3] <- omit_variance_vector
omit_mse_bias_sq_var_df <- data.frame(omit_mse_bias_sq_var_matrix)
colnames(omit_mse_bias_sq_var_df) <- c("mse_omit","bias_omit","variance_omit")
omit_mse_bias_sq_var_df


isTRUE(all.equal(omit_bias_sq_vector + omit_variance_vector, omit_mse_vector) )

omit_should_equal_mse = omit_bias_sq_vector + omit_variance_vector
omit_decomp_misfit = omit_should_equal_mse - omit_mse_vector
omit_decomp_misfit 

best_omit_df <- data.frame(cbind(best_mse_bias_sq_var_df,omit_mse_bias_sq_var_df)) 
best_omit_tib <- as_tibble(best_omit_df)
best_omit_tib <- best_omit_tib %>%
  mutate(year=c(0:9)) %>%
  mutate(bias_sq_plus_variance_best = bias_best+variance_best) %>%
  mutate(bias_sq_plus_variance_omit = bias_omit+variance_omit) 

best_omit_tib

best_omit_compare_mse <- ggplot(data = best_omit_tib) +
  geom_line(mapping = aes(x = year, y = mse_best)) +
  geom_line(mapping = aes(x = year, y = mse_omit, color="omit"))

best_omit_compare_bias <- ggplot(data = best_omit_tib) +
  geom_line(mapping = aes(x = year, y = bias_best)) +
  geom_line(mapping = aes(x = year, y = bias_omit, color="omit"))

best_omit_compare_variance <- ggplot(data = best_omit_tib) +
  geom_line(mapping = aes(x = year, y = variance_best)) +
  geom_line(mapping = aes(x = year, y = variance_omit, color="omit"))


best_verify_bias_variance_decomp <- ggplot(data = best_omit_tib) +
  geom_line(mapping = aes(x = year, y = mse_best, color="mse_best")) +
  geom_line(mapping = aes(x = year, y = bias_sq_plus_variance_best ))

omit_verify_bias_variance_decomp <- ggplot(data = best_omit_tib) +
  geom_line(mapping = aes(x = year, y = mse_omit, color="mse_omit")) +
  geom_line(mapping = aes(x = year, y = bias_sq_plus_variance_omit ))

plot_grid(best_omit_compare_mse, best_omit_compare_bias, best_omit_compare_variance,  labels = "AUTO")

plot_grid( best_verify_bias_variance_decomp, omit_verify_bias_variance_decomp, labels = "AUTO")

```



```{r chunk10e2b, eval=FALSE}
get_bias = function(estimate, truth) {
  mean(estimate) - truth
}

predictions_mean = apply(prediction2, 1, mean)

get_var = function(estimate) {
  mean((estimate - mean(estimate)) ^ 2)
}

bias = apply(sim_data_all3_df, 2, get_bias, truth = f(x = -2.7))
variance = apply(predictions, 2, get_var)
mse = apply(predictions, 2, get_mse, truth = f(x = -2.7))
bias
variance
mse
mse_p10_omit <- mean( (sim_data_cen_p10_omit$cb28sim - sim_data$cb28sim) ^2 )

```







```{r chunk10e2, eval=FALSE}
  # fit models: omission, sub with 1/sqrt(2), cenreg()
  
  # LOQ_p10 = quantile(sim_data$cb28, probs=0.1)
  # sim_data_cen_p10_omit <- sim_data %>%
  #   filter(cb28 >= LOQ_p10 )
  # p10_omit_fit = lm(cb28 ~ year, data=sim_data_cen_p10_omit)
  # 
  # sim_data_cen_p10_sub <- sim_data %>%
  #   mutate(cb28sim = pmax(cb28sim, LOQ_p10 - log(sqrt(2) ) ) ) 
  # p10_sub_fit = lm(cb28 ~ year, data=sim_data_cen_p10_sub)

  # get predictions at x=5. 5 years after year zero
     


  # predictions[iter, 2] = predict(p10_omit_fit, x=data.frame(x = 5) )
  
  # predictions[iter, 3] = predict(p10_sub_fit, x=data.frame(x = 5) )
  
  # predictions[iter, 4] = predict(p10_cenreg_fit, x=data.frame(x = 5) )

sim_data2 <- get_sim_data(sample_size=12)


true_fit2 <- lm(data_geomean2$cb28 ~ data_geomean2$year)
predict_df2 <- as.data.frame(predict(true_fit2) )
predict_df2
# predict_df2 <- as.data.frame(predict(true_fit2) )
# predict_tib2 <- as_tibble(predict_df2)
# predict_means_tib2 <- predict_tib2 %>%
#   group_by(year) %>%
#   summarise_at(vars(cb28sim, cb153sim), geomean_prelogged  ) %>%
#   ungroup()
# predict_means_tib2
# 
# exp(mean(cb153))
# x = data.frame(x = 5) # fixed point at which we make predictions
```


```{r chunk10f, eval=FALSE}

predictions <- matrix(0, nrow = n_iter, ncol = 1)
# x=data.frame(x = 5)

for (iter in 1:n_iter) {

  # simulate new, random, training data
  # this is the only random portion of the bias, var, and mse calculations
  # this allows us to calculate the expectation over D

  sim_data = get_sim_data(sample_size = 12)
  data_tib <- as_tibble(sim_data)
  data_means <- data_tib %>%
    group_by(year) %>%
    summarise_at(vars(cb28sim, cb153sim), mean  ) %>%
    ungroup()
  true_fit = lm(data_means$cb28 ~ data_means$year)
  # fit models: omission, sub with 1/sqrt(2), cenreg()
  
  # LOQ_p10 = quantile(sim_data$cb28, probs=0.1)
  # sim_data_cen_p10_omit <- sim_data %>%
  #   filter(cb28 >= LOQ_p10 )
  # p10_omit_fit = lm(cb28 ~ year, data=sim_data_cen_p10_omit)
  # 
  # sim_data_cen_p10_sub <- sim_data %>%
  #   mutate(cb28sim = pmax(cb28sim, LOQ_p10 - log(sqrt(2) ) ) ) 
  # p10_sub_fit = lm(cb28 ~ year, data=sim_data_cen_p10_sub)

  # get predictions at x=5. 5 years after year zero
  predictions(, iter) = as.data.frame(predict(true_fit) )  


  # predictions[iter, 2] = predict(p10_omit_fit, x=data.frame(x = 5) )
  
  # predictions[iter, 3] = predict(p10_sub_fit, x=data.frame(x = 5) )
  
  # predictions[iter, 4] = predict(p10_cenreg_fit, x=data.frame(x = 5) )

}
```

```{r chunk10g, eval=FALSE}
year=0
for(year in 0:9) {get_sim_data(f, year)}


# cb28true = -4.7116719 -0.0334808 * year_sim


mse_p10_omit <- mean( (sim_data_cen_p10_omit$cb28sim - sim_data$cb28sim) ^2 )
# above does not work because lengths do not match
# perhaps I must fit models and simulate from those, like Dalpiak does.
mse_p10_sub <- mean( (sim_data_cen_p10_sub$cb28sim - sim_data$cb28sim) ^2 )
mse_p10_cenreg <- mean( (sim_data_cen_p10_cenreg_pred$cb28sim - sim_data$cb28sim) ^2 )
mse_p10_omit 
mse_p10_sub
mse_p10_cenreg

# bias_p10_omit <- mean()


```


```{r chunk10h, eval=FALSE}
get_mse = function(truth, estimate) {
  mean((estimate - truth) ^ 2)
}

get_bias = function(estimate, truth) {
  mean(estimate) - truth
}

get_var = function(estimate) {
  mean((estimate - mean(estimate)) ^ 2)
}

bias = apply(sim_data_all3_df, 2, get_bias, truth = f(x = -2.7))
variance = apply(predictions, 2, get_var)
mse = apply(predictions, 2, get_mse, truth = f(x = -2.7))
bias
variance
mse
```

We will now fit a linear model CB28 ~ YEAR for the three datasets from our three methods.

```{r chunk10i, eval=FALSE}

# set.seed(1)
# for (iter in 1:niter) {

  # simulate new, random, training data
  # this is the only random portion of the bias, var, and mse calculations
  # this allows us to calculate the expectation over D

  # sim_data = get_sim_data(f)

  # fit models: omission, sub with 1/sqrt(2), cenreg()
  # fit_0 = lm(y ~ 1,                   data = sim_data)

  # fit_1 = lm(y ~ poly(x, degree = 1), data = sim_data)

  # fit_2 = lm(y ~ poly(x, degree = 2), data = sim_data)
  # fit_9 = lm(y ~ poly(x, degree = 9), data = sim_data)

  # get predictions

  # predictions[sim, 1] = predict(fit_0, x)

  # predictions[sim, 1] = predict(fit_1, x)

  # predictions[sim, 3] = predict(fit_2, x)
  # predictions[sim, 4] = predict(fit_9, x)
 }


sim_data_cen_p10_omit_fit <- lm(sim_data_mean_cen_p10_omit$cb28sim ~ sim_data_mean_cen_p10_omit$year_sim)

sim_data_cen_p10_sub_fit <- lm(sim_data_mean_cen_p10_sub$cb28sim ~ sim_data_mean_cen_p10_sub$year_sim)

sim_data_cen_p10_cenreg_pred_fit <- lm(sim_data_mean_cen_p10_cenreg_pred$cb28sim ~ sim_data_mean_cen_p10_cenreg_pred$year_sim)

summary(sim_data_cen_p10_omit_fit)
summary(sim_data_cen_p10_sub_fit)
summary(sim_data_cen_p10_cenreg_pred_fit)

```

I will try a second method of simulating the data (based on Dalpiak's book), variables have a 2 at their end to distinguish these from those from the first method.

```{r chunk11, eval=FALSE}
# attach(sim_data)
sim_data_cen_p10_omit <- sim_data %>%
  filter(cb28sim>=LOQ_p10)

# x is cb153, y is cb28
f = function(x) {
  -3.12 + 0.86*x  # Regression equation for CB28 ~ CB153 from obs data
}

# sample_size=3
sim_data4 = matrix(0, nrow = niter, ncol = 3)
sim_data4

get_sim_data = function(f) { 
  year = c(0:9)
  eps = rnorm(n = 1, mean = 0, sd = 0.5) #epsilon. sd is from obs data
  x = -1.85 - 0.039*year + eps # Regression equation for CB153 ~ YEAR from obs data
  y = f(x) + eps
  sim_data4[year, ] = c(year,x,y)
  # data.frame(sim_data4) # x is CB153, y is CB28
}
year=0
for(year in 0:9) {get_sim_data(f, year)}
  
  


# fit_cb = lm(y ~ poly(x2, degree = 1), data = sim_data2)


# sim_pred_cen_p10_omit = function(x) {

  # x (year) value to predict at
  # coerce to data frame for predict() function
  
  # x = data.frame(x = x)

  # simulate new training data
  # expectation over D
  
  #sim_data = get_sim_data(f)

  # fit models
  
  # fit_cb1 = lm(y ~ poly(x, degree = 1), data = sim_data2) #fit to CB28 ~ CB153
  # get prediction at point for each model
  
  # predict(fit_cb1, x)
# }

# set.seed(1)
# n_sims = 250
# n_models = 1
# x = data.frame(x = -2.7) # fixed point at which we make predictions (~median CB153)
# predictions = matrix(0, nrow = n_sims, ncol = n_models)
```


```{r chunk11b}



# year_for_prediction_df <- as.data.frame(sim_data_cen_p10_omit$year_sim
# )
# 
# p10_omit_pred_year10 <- predict(sim_data_cen_p10_omit_fit, year_for_prediction_df)
# sd(p10_omit_pred_year10)
# str(p10_omit_pred_year10)
# glimpse(sim_data_cen_p10_omit)
# glimpse(sim_data_cen_p10_sub)
# glimpse(sim_data_cen_p10_cenreg_pred)

# cb28sim_cen_p10_sub <- pmax(cb28sim, LOQ_p10/sqrt(2)) 
# cb28sim_cen_p50_sub <- pmax(cb28sim, LOQ_p50/sqrt(2)) 
# cb28sim_cen_p90_sub <- pmax(cb28sim, LOQ_p90/sqrt(2)) 
# 
# 
# 
# 
# cb28sim_pred_p10 <- ifelse(cb28sim == cb28sim_cens_p10,  cb28sim, predict( lm(CB28~CB153+YEAR) ) )
# cb28sim_pred_p50 <- ifelse(cb28sim == cb28sim_cens_p50,  cb28sim, predict( lm(CB28~CB153+YEAR) ) )
# cb28sim_pred_p90 <- ifelse(cb28sim == cb28sim_cens_p90,  cb28sim, predict( lm(CB28~CB153+YEAR) ) )
# 
# testdata_cen_omit_logconc_tib <- as_tibble(testdata_cen_omit_logconc)

# ggplot(testdata_cen_omit_logconc_tib, aes(x=YEAR, y=CB28)) + 
#   geom_point() + 
#   ylim(-7,-3) 
# 
# data_from_pred_p10 <- cbind(cb28sim_pred_p10, cb153sim, year_sim)  
# tib_from_pred_p10 <- as_tibble(data_from_pred_p10)
# tib_from_pred_p10_mean <- tib_from_pred_p10 %>%
#   group_by(year_sim) %>%
#   summarise_at(vars(cb28sim_pred_p10, cb153sim), mean  ) %>%
#   ungroup()  
# 
# 
# data_from_pred_p50 <- cbind(cb28sim_pred_p50, cb153sim, year_sim)  
# tib_from_pred_p50 <- as_tibble(data_from_pred_p50)
# tib_from_pred_p50_mean <- tib_from_pred_p50 %>%
#   group_by(year_sim) %>%
#   summarise_at(vars(cb28sim_pred_p50, cb153sim), mean  ) %>%
#   ungroup() 
# 
# data_from_pred_p90 <- cbind(cb28sim_pred_p90, cb153sim, year_sim)  
# tib_from_pred_p90 <- as_tibble(data_from_pred_p90)
# tib_from_pred_p90_mean <- tib_from_pred_p90 %>%
#   group_by(year_sim) %>%
#   summarise_at(vars(cb28sim_pred_p90, cb153sim), mean  ) %>%
#   ungroup() 
# 
#   
#   
# ggplot(tib_from_sim_mean, aes(x=year_sim, y=cb28sim)) + 
#   geom_point() + 
#   ylim(-7,-3) 


# glimpse(cb28_pred_geomean)
# ggplot(data = pcb_tib4m_utlaengan_he) + 
#   geom_point(mapping = aes(x = CB138, y = CB153, color = YEAR))

# par( mfrow=(c(2,2) ) )
# plot(testdata_cen_omit_logconc$CB28 ~ testdata_cen_omit_logconc$YEAR, ylim=c(-7,-3))
# plot(tib_from_sim_mean$cb28sim ~ tib_from_sim_mean$year_sim, ylim=c(-7,-3))
# plot(testdata_cen_omit_logconc$CB28 ~ testdata_cen_omit_logconc$CB153, ylim=c(-7,-3))
# plot(tib_from_sim_mean$cb28sim ~ tib_from_sim_mean$cb153sim, ylim=c(-7,-3))
# 
# 
# par( mfrow=(c(2,2) ) )
# plot(testdata_cen_omit_logconc$CB28 ~ testdata_cen_omit_logconc$YEAR, ylim=c(-7,-3))
# plot(tib_from_sim_mean$cb28sim ~ tib_from_sim_mean$year_sim, ylim=c(-7,-3))
# plot(testdata_cen_omit_logconc$CB28 ~ testdata_cen_omit_logconc$CB153, ylim=c(-7,-3))
# plot(tib_from_sim_mean$cb28sim ~ tib_from_sim_mean$cb153sim, ylim=c(-7,-3))



# par( mfrow=(c(2,2) ) )
# plot(testdata_cen_omit_logconc$CB28 ~ testdata_cen_omit_logconc$YEAR, ylim=c(-7,-3))
# plot(tib_from_pred_p10_mean$cb28sim_pred_p10 ~ tib_from_pred_p10_mean$year_sim, ylim=c(-7,-3))
# plot(testdata_cen_omit_logconc$CB28 ~ testdata_cen_omit_logconc$CB153, ylim=c(-7,-3))
# plot(tib_from_pred_p10_mean$cb28sim_pred_p10 ~ tib_from_pred_p10_mean$cb153sim, ylim=c(-7,-3))
# 
# 
# par( mfrow=(c(2,2) ) )
# plot(testdata_cen_omit_logconc$CB28 ~ testdata_cen_omit_logconc$YEAR, ylim=c(-7,-3))
# plot(tib_from_pred_p50_mean$cb28sim_pred_p50 ~ tib_from_pred_p50_mean$year_sim, ylim=c(-7,-3))
# plot(testdata_cen_omit_logconc$CB28 ~ testdata_cen_omit_logconc$CB153, ylim=c(-7,-3))
# plot(tib_from_pred_p50_mean$cb28sim_pred_p50 ~ tib_from_pred_p50_mean$cb153sim, ylim=c(-7,-3))
# 
# par( mfrow=(c(2,2) ) )
# plot(testdata_cen_omit_logconc$CB28 ~ testdata_cen_omit_logconc$YEAR, ylim=c(-7,-3))
# plot(tib_from_pred_p90_mean$cb28sim_pred_p90 ~ tib_from_pred_p90_mean$year_sim, ylim=c(-7,-3))
# plot(testdata_cen_omit_logconc$CB28 ~ testdata_cen_omit_logconc$CB153, ylim=c(-7,-3))
# plot(tib_from_pred_p90_mean$cb28sim_pred_p90 ~ tib_from_pred_p90_mean$cb153sim, ylim=c(-7,-3))
```

Linear models for $(x,y)=(CB28,YEAR)$ and for $(x,y)=(CB28,CB153)$ respectively were each fitted to data with 10%, 50%, 90% censored observations substituted by imputed values, respectively.  The adjusted $R^{2}$ values decreased as the proportion of censored observations increased, which reflects the fact that the non-censored values were simulated whereas the censored values were predicted from the linear model that was fitted to the observed data.  

```{r chunk12}

# tib_from_pred_p10_mean_cb28_year_fit <- lm(tib_from_pred_p10_mean$cb28sim_pred_p10 ~ tib_from_pred_p10_mean$year_sim)
# 
# tib_from_pred_p10_mean_cb28_cb153_fit <- lm(tib_from_pred_p10_mean$cb28sim_pred_p10 ~ tib_from_pred_p10_mean$cb153sim)
# 
# tib_from_pred_p50_mean_cb28_year_fit <- lm(tib_from_pred_p50_mean$cb28sim_pred_p50 ~ tib_from_pred_p50_mean$year_sim)
# 
# tib_from_pred_p50_mean_cb28_cb153_fit <- lm(tib_from_pred_p50_mean$cb28sim_pred_p50 ~ tib_from_pred_p50_mean$cb153sim)
# 
# tib_from_pred_p90_mean_cb28_year_fit <- lm(tib_from_pred_p90_mean$cb28sim_pred_p90 ~ tib_from_pred_p90_mean$year_sim)
# 
# tib_from_pred_p90_mean_cb28_cb153_fit <- lm(tib_from_pred_p90_mean$cb28sim_pred_p90 ~ tib_from_pred_p90_mean$cb153sim)
# 
# summary(tib_from_pred_p10_mean_cb28_year_fit)
# summary(tib_from_pred_p10_mean_cb28_cb153_fit)
# 
# summary(tib_from_pred_p50_mean_cb28_year_fit)
# summary(tib_from_pred_p50_mean_cb28_cb153_fit)
# 
# summary(tib_from_pred_p90_mean_cb28_year_fit)
# summary(tib_from_pred_p90_mean_cb28_cb153_fit)





# plot(log(testdata1$CB28) ~ log(testdata1$CB153), ylim(-7,-3) )
# plot(cb28sim ~ cb153sim, ylim(-7,-3))
# quantile(cb28sim, probs=c(0.1,0.3,0.5) ) # (-5.76, -5.32, -5.22)
# sd(cb28sim)
# str(cb28sim)
# str(cb28sim_cens_p10)
# str(cb28sim_pred_p10)
# sum(cb28sim==cb28sim_cens_p10)
# sd(cb28sim_pred_p10)
# str(cb28sim_cens_p50)
# str(cb28sim_pred_p50)
# sum(cb28sim==cb28sim_cens_p50)
# sd(cb28sim_pred_p50)
# str(cb28sim)
# str(cb28sim_cens_p10)
# str(cb28sim_pred_p10)


```








